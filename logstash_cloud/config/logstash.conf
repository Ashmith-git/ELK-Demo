input {
	tcp {
		port => 5101
		codec => "json_lines"
	}
  http {
    port => 5102
    type => "heroku"
    tags => ["heroku"]
  }
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		index => "logstash-cloud-%{+YYYY.MM.dd}"
	}
}

filter {
  if [type] == "heroku" {
    split {}
    grok {
     match => {
        "message" => "%{SYSLOG5424PRI}%{NONNEGINT:syslog5424_ver} +(?:%{TIMESTAMP_ISO8601:timestamp}|-) +(?:%{HOSTNAME:logplex_host}|-) +(?:%{WORD:logplex_source}|-) +(?:%{DATA:logplex_dyno}|-) +(-) +%{GREEDYDATA:logplex_message}"
      }
    }
    mutate {
      rename => { "logplex_source" => "heroku_source" }
      rename => { "logplex_dyno" => "heroku_dyno" }
    }
    kv {
      source => "logplex_message"
      prefix => "kv_"
      include_keys => [
        #
        # HTTP router information
        #
        "dyno",
        "method",
        "path",
        "host",
        "request_id",
        "fwd",
        "connect",
        "service",
        "status",
        "bytes",
        #
        # log-runtime-metrics memory, swap information, and
        # CPU load averages information
        #
        "source",
        "dyno",
        "sample#memory_total",
        "sample#memory_rss",
        "sample#memory_cache",
        "sample#memory_swap",
        "sample#memory_pgpgin",
        "sample#memory_pgpgout",
        "sample#memory_quota",
        "sample#load_avg_1m",
        "sample#load_avg_5m",
        "sample#load_avg_15m",
        #
        # Error information
        #
        "code",
        "desc"
      ]
    }

    mutate {
      rename => { "logplex_message" => "message" }
      # rename HTTP router fields
      rename => { "kv_method" => "heroku_http_method" }
      rename => { "kv_path" => "heroku_http_path" }
      rename => { "kv_host" => "heroku_http_host" }
      rename => { "kv_request_id" => "heroku_http_request_id" }
      rename => { "kv_fwd" => "heroku_http_fwd" }
      rename => { "kv_connect" => "heroku_http_connect_ms" }
      rename => { "kv_service" => "heroku_http_service_ms" }
      rename => { "kv_status" => "heroku_http_status" }
      rename => { "kv_bytes" => "heroku_http_bytes" }
      # rename log-runtime-metrics fields
      rename => { "kv_sample#memory_total" => "heroku_memory_total_mb" }
      rename => { "kv_sample#memory_rss" => "heroku_memory_rss_mb" }
      rename => { "kv_sample#memory_cache" => "heroku_memory_cache_mb" }
      rename => { "kv_sample#memory_swap" => "heroku_memory_swap_mb" }
      rename => { "kv_sample#memory_pgpgin" => "heroku_memory_pgpgin_pages" }
      rename => { "kv_sample#memory_pgpgout" => "heroku_memory_pgpgout_pages" }
      rename => { "kv_sample#memory_quota" => "heroku_memory_quota_mb" }
      rename => { "kv_sample#load_avg_1m" => "heroku_load_avg_1m" }
      rename => { "kv_sample#load_avg_5m" => "heroku_load_avg_5m" }
      rename => { "kv_sample#load_avg_15m" => "heroku_load_avg_15m" }
      # rename error fields
      rename => { "kv_code" => "heroku_error_code" }
      rename => { "kv_desc" => "heroku_error_description" }

      # convert values to numbers where appropriate,
      # first removing prefixes
      gsub => [
        "heroku_http_connect_ms", "ms", "",
        "heroku_http_service_ms", "ms", "",
        "heroku_memory_total_mb", "MB", "",
        "heroku_memory_rss_mb", "MB", "",
        "heroku_memory_cache_mb", "MB", "",
        "heroku_memory_quota_mb", "MB", "",
        "heroku_memory_pgpgin_pages", "pages", "",
        "heroku_memory_pgpgout_pages", "pages", ""
      ]
      convert => [
        "heroku_http_connect_ms", "integer",
        "heroku_http_service_ms", "integer",
        "heroku_http_bytes", "integer",
        "heroku_http_status", "integer",
        "heroku_memory_total_mb", "float",
        "heroku_memory_rss_mb", "float",
        "heroku_memory_cache_mb", "float",
        "heroku_memory_swap_mb", "float",
        "heroku_memory_quota_mb", "float",
        "heroku_memory_pgpgin_pages", "integer",
        "heroku_memory_pgpgout_pages", "integer",
        "heroku_load_avg_1m", "float",
        "heroku_load_avg_5m", "float",
        "heroku_load_avg_15m", "float"
      ]
    }

    # get the application's name from the URL
    mutate {
      rename => { "[headers][request_path]" => "heroku_app_name" }
      gsub => ["heroku_app_name", "/", ""]
      add_field => { "source" => "%{heroku_app_name}" }
      remove_field => [
        "headers"
      ]
    }

    # use heroku's timestamp
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }

    # Extract syslog information from the `PRI` field.
    # This is needed to get the severity-related fields!
    syslog_pri { syslog_pri_field_name => "syslog5424_pri" }
    # set `syslog_severity` based on `syslog_severity_code`,
    # according to the syslog.conf(5) man page
    if [syslog_severity_code] == 0 {
      mutate {
        update => { "syslog_severity" => "emerg" }
      }
    } else if [syslog_severity_code] == 1 {
      mutate {
        update => { "syslog_severity" => "alert" }
      }
    } else if [syslog_severity_code] == 2 {
      mutate {
        update => { "syslog_severity" => "crit" }
      }
    } else if [syslog_severity_code] == 3 {
      mutate {
        update => { "syslog_severity" => "err" }
      }
    } else if [syslog_severity_code] == 4 {
      mutate {
        update => { "syslog_severity" => "warning" }
      }
    } else if [syslog_severity_code] == 5 {
      mutate {
        update => { "syslog_severity" => "notice" }
      }
    } else if [syslog_severity_code] == 6 {
      mutate {
        update => { "syslog_severity" => "info" }
      }
    } else if [syslog_severity_code] == 7 {
      mutate {
        update => { "syslog_severity" => "debug" }
      }
    }
    mutate {
      rename => { "syslog_severity" => "severity" }
      rename => { "syslog_severity_code" => "severity_code" }
      remove_field => [
        "logplex_host",
        "syslog5424_pri",
        "syslog5424_ver",
        "syslog_facility",
        "syslog_facility_code"
      ]
    }

    # add tag `error` if an error was reported
    if [heroku_error_code] =~ /.+/ {
      mutate {
        add_tag => ["error"]
      }
    }

    # In the HTTP router reports, field "dyno" is the
    # "name of the dyno that serviced the request". However,
    # in log-runtime-metrics reports, that same field is
    # "the app id and a UUID that unique identifies every
    # distinct dyno run on the platform".
    if [heroku_http_request_id] =~ /.+/ {
      mutate {
        rename => { "kv_dyno" => "heroku_service_dyno" }
        add_field => { "http_method" => "%{heroku_http_method}" }
        add_field => { "http_path" => "%{heroku_http_path}" }
        add_field => { "http_content_length" => "%{heroku_http_bytes}" }
        add_field => { "http_status" => "%{heroku_http_status}" }
        add_field => { "request_id" => "%{heroku_http_request_id}" }
        add_field => { "response_time_ms" => "%{heroku_http_service_ms}" }
        add_tag => ["http"]
      }
    } else if [heroku_memory_total_mb] or [heroku_load_avg_1m] {
      mutate {
        rename => { "kv_dyno" => "heroku_source_dyno_id" }
        rename => { "kv_source" => "heroku_source_dyno" }
        add_tag => ["runtime_metrics"]
      }
    } else if [heroku_error_code] !~ /.+/ {
      # drop only if no error was reported
      drop {}
    }
  }

  mutate {
    # remove color codes
    gsub => ["message", "\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]", ""]
  }
}
